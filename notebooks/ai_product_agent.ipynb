{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53638f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-community fastapi uvicorn requests duckduckgo-search aiohttp nest_asyncio psutil tenacity yandexcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0508ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в ячейке ноутбука\n",
    "%pip install -U nbformat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f253a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib seaborn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f67ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de6812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c2af8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mini_langsmith import (\n",
    "#     Tracer, attach_logger, parse_logs_to_df,\n",
    "#     show_span_tree, summarize, spans_to_dataframe, export_spans\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bf5d5b",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "008d2f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import threading\n",
    "import uvicorn\n",
    "import requests\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import psutil\n",
    "import socket\n",
    "import json\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain_community.llms import YandexGPT\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "import re\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import uuid\n",
    "import aiohttp\n",
    "# from prometheus_client import Counter, Histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f4865c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply nest_asyncio for Jupyter compatibility\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e65982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename='system.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e804102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91058d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "FODLER_ID =  os.getenv(\"FOLDER_ID\")\n",
    "API_KEY =  os.getenv(\"API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035a2aa",
   "metadata": {},
   "source": [
    "# Логи и трассировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea091f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf472d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\ai_product_hack\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a737d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(str(\"multiagent_tracer/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c88b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from multiagent_tracer import (\n",
    "    MultiAgentTracer, AgentType,\n",
    "    trace_agent, trace_async_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3de06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from multiagent_tracer import AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a52d236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracer session_id = notebook_session\n"
     ]
    }
   ],
   "source": [
    "tracer = MultiAgentTracer(\n",
    "    session_id=\"notebook_session\",\n",
    "    log_file=None,                 # можно указать путь к файлу .log\n",
    "    enable_real_time_viz=False,    # True — если хотите обновление графа на лету\n",
    ")\n",
    "print(f\"Tracer session_id = {tracer.session_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe188df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "import logging, sys, json\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import time\n",
    "from starlette.middleware.base import BaseHTTPMiddleware\n",
    "import uuid\n",
    "from typing import Callable, Optional\n",
    "from langchain.callbacks.base import BaseCallbackHandler\n",
    "from starlette.responses import Response\n",
    "from fastapi import Request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def trace_block(agent_name: str,\n",
    "                agent_type: AgentType = AgentType.CUSTOM,\n",
    "                parent_event_id: str | None = None,\n",
    "                **data):\n",
    "    eid = tracer.start_trace(\n",
    "        agent_name=agent_name,\n",
    "        agent_type=agent_type,\n",
    "        data=data,\n",
    "        parent_event_id=parent_event_id\n",
    "    )\n",
    "    try:\n",
    "        yield eid\n",
    "    except Exception as e:\n",
    "        # фикс: логируем и ЗДЕСЬ же безопасно перекидываем исключение\n",
    "        tracer.log_error(agent_name, e, parent_event_id=eid)\n",
    "        tracer.end_trace(eid, {\"error\": str(e)}, success=False)\n",
    "        raise\n",
    "    else:\n",
    "        # если исключения не было — закрываем с success=True\n",
    "        tracer.end_trace(eid, {\"success\": True}, success=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab4c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "MAX_LOG_CHARS = 2000\n",
    "\n",
    "def _safe_text(b: bytes) -> str:\n",
    "    try:\n",
    "        return b.decode(\"utf-8\", errors=\"replace\")\n",
    "    except Exception:\n",
    "        return \"<binary>\"\n",
    "\n",
    "def _truncate(s: str, n: int = MAX_LOG_CHARS) -> str:\n",
    "    return s if len(s) <= n else s[:n] + \"...<truncated>\"\n",
    "\n",
    "class AccessLogMiddleware(BaseHTTPMiddleware):\n",
    "    def __init__(self, app, service_name: str, log_fn: Callable[[dict], None]):\n",
    "        super().__init__(app)\n",
    "        self.service_name = service_name\n",
    "        self.log_fn = log_fn\n",
    "\n",
    "    async def dispatch(self, request, call_next):\n",
    "        trace_id = request.headers.get(\"X-Request-Id\", str(uuid.uuid4()))\n",
    "        start_ts = time.time()\n",
    "\n",
    "        # --- Request logging\n",
    "        raw_req = await request.body()\n",
    "        self.log_fn(\n",
    "            service=self.service_name,\n",
    "            event=\"request_in\",\n",
    "            trace_id=trace_id,\n",
    "            method=request.method,\n",
    "            path=str(request.url.path),\n",
    "            body=_truncate(_safe_text(raw_req)),\n",
    "        )\n",
    "\n",
    "        # --- Call downstream\n",
    "        resp = await call_next(request)\n",
    "\n",
    "        # Drain body_iterator to log response body\n",
    "        body = b\"\"\n",
    "        async for chunk in resp.body_iterator:\n",
    "            body += chunk\n",
    "\n",
    "        # Preserve headers & content type\n",
    "        headers = dict(resp.headers)\n",
    "        if \"content-type\" not in {k.lower(): v for k, v in headers.items()}:\n",
    "            # Умная догадка: если это JSON-подобно — ставим JSON\n",
    "            if body[:1] in (b\"{\", b\"[\"):\n",
    "                headers[\"content-type\"] = \"application/json; charset=utf-8\"\n",
    "            else:\n",
    "                headers[\"content-type\"] = \"text/plain; charset=utf-8\"\n",
    "\n",
    "        # Rebuild response WITHOUT media_type arg, чтобы не перезаписать content-type\n",
    "        new_resp = Response(\n",
    "            content=body,\n",
    "            status_code=resp.status_code,\n",
    "            headers=headers,\n",
    "        )\n",
    "\n",
    "        # --- Response logging\n",
    "        self.log_fn(\n",
    "            service=self.service_name,\n",
    "            event=\"response_out\",\n",
    "            trace_id=trace_id,\n",
    "            status=resp.status_code,\n",
    "            duration_ms=int((time.time() - start_ts) * 1000),\n",
    "            body=_truncate(_safe_text(body)),\n",
    "        )\n",
    "        return new_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c7948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "def setup_logging(log_path=\"orchestrator.log\"):\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    if not logger.handlers:\n",
    "        fh = RotatingFileHandler(log_path, maxBytes=5_000_000, backupCount=3, encoding=\"utf-8\")\n",
    "        sh = logging.StreamHandler(sys.stdout)\n",
    "        fmt = logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "        fh.setFormatter(fmt); sh.setFormatter(fmt)\n",
    "        logger.addHandler(fh); logger.addHandler(sh)\n",
    "\n",
    "def log_json(**kwargs):\n",
    "    logging.info(json.dumps(kwargs, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92500fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "async def log_trace(event: str, **fields):\n",
    "    fields.update({\n",
    "        \"ts\": time.time(),\n",
    "        \"event\": event\n",
    "    })\n",
    "    log_json(**fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b8725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: custom_trace.py\n",
    "class LoggingCallback(BaseCallbackHandler):\n",
    "    def __init__(self, log_fn: Optional[Callable[..., None]] = None, log_file: str = \"trace_log.log\"):\n",
    "        self.log_fn = log_fn\n",
    "        self.log_file = log_file\n",
    "\n",
    "    def _emit(self, **fields):\n",
    "        # в файл (чтобы всегда что-то писалось)\n",
    "        ts = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        line = f\"[{ts}] \" + \" \".join(f\"{k}={repr(v)[:500]}\" for k, v in fields.items())\n",
    "        with open(self.log_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(line + \"\\n\")\n",
    "        # в внешний логгер, если передан\n",
    "        if self.log_fn:\n",
    "            try:\n",
    "                self.log_fn(**fields)  # ИМЕНОВАННЫЕ аргументы!\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"LoggingCallback log_fn failed: {e}\")\n",
    "\n",
    "    # LLM события\n",
    "    def on_llm_start(self, serialized, prompts, **kwargs):\n",
    "        self._emit(event=\"llm_start\", prompts=prompts)\n",
    "\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        try:\n",
    "            text = response.generations[0][0].text\n",
    "        except Exception:\n",
    "            text = str(response)\n",
    "        self._emit(event=\"llm_end\", text=text[:2000])\n",
    "\n",
    "    # Цепочки\n",
    "    def on_chain_start(self, serialized, inputs, **kwargs):\n",
    "        self._emit(event=\"chain_start\", inputs=inputs)\n",
    "\n",
    "    def on_chain_end(self, outputs, **kwargs):\n",
    "        self._emit(event=\"chain_end\", outputs=str(outputs)[:2000])\n",
    "\n",
    "    # Инструменты\n",
    "    def on_tool_start(self, serialized, input_str, **kwargs):\n",
    "        self._emit(event=\"tool_start\", tool=serialized.get(\"name\"), input=str(input_str)[:500])\n",
    "\n",
    "    def on_tool_end(self, output, **kwargs):\n",
    "        self._emit(event=\"tool_end\", output=str(output)[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf0fa21",
   "metadata": {},
   "source": [
    "# Инициализация ЛЛМ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a92381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# 1. Определяем Pydantic модели для всех агентов\n",
    "class TaskRequest(BaseModel):\n",
    "    input: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a84a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# Initialize YandexGPT LLM\n",
    "llm = YandexGPT(\n",
    "    api_key=API_KEY,\n",
    "    folder_id=FODLER_ID,\n",
    "    temperature=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "class RouteDecision(BaseModel):\n",
    "    next_agent: str = Field(pattern=\"^(SEARCH_AGENT|ANALYSIS_AGENT|REPORT_AGENT)$\")\n",
    "    reason: str\n",
    "    input: str\n",
    "\n",
    "class RouterAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.router_prompt = PromptTemplate.from_template(\n",
    "            \"\"\"You are a strict router. Choose the next agent.\n",
    "\n",
    "            Available agents:\n",
    "            - SEARCH_AGENT: use ONLY when fresh/current web info is needed or no context yet.\n",
    "            - ANALYSIS_AGENT: process/summarize/structure text snippets.\n",
    "            - REPORT_AGENT: produce final structured answer (last step).\n",
    "\n",
    "            Return ONLY a JSON object (no prose, no Markdown fences).\n",
    "\n",
    "            Input query: {query}\n",
    "            Current context: {context}\n",
    "\n",
    "            JSON schema:\n",
    "            {{\n",
    "            \"next_agent\": \"SEARCH_AGENT|ANALYSIS_AGENT|REPORT_AGENT\",\n",
    "            \"reason\": \"string\",\n",
    "            \"input\": \"string\"\n",
    "            }}\"\"\"\n",
    "        )\n",
    "\n",
    "    def _extract_json(self, s: str) -> dict:\n",
    "        # 1) попробуем прямой json.loads\n",
    "        try:\n",
    "            return json.loads(s)\n",
    "        except Exception:\n",
    "            pass\n",
    "        # 2) выцепим самый длинный JSON-блок фигурных скобок (устойчивее, чем {[^}]*})\n",
    "        candidates = []\n",
    "        stack = []\n",
    "        start = None\n",
    "        for i, ch in enumerate(s):\n",
    "            if ch == '{':\n",
    "                if not stack:\n",
    "                    start = i\n",
    "                stack.append('{')\n",
    "            elif ch == '}':\n",
    "                if stack:\n",
    "                    stack.pop()\n",
    "                    if not stack and start is not None:\n",
    "                        candidates.append(s[start:i+1])\n",
    "        candidates.sort(key=len, reverse=True)\n",
    "        for c in candidates:\n",
    "            try:\n",
    "                return json.loads(c)\n",
    "            except Exception:\n",
    "                continue\n",
    "        raise ValueError(\"No valid JSON found in router output\")\n",
    "\n",
    "    def route(self, query: str, context: str = \"No context yet\"):\n",
    "        try:\n",
    "            chain = self.router_prompt | self.llm\n",
    "            raw = chain.invoke({\"query\": query, \"context\": context})\n",
    "            data = self._extract_json(raw)\n",
    "            decision = RouteDecision(**data)  # валидация\n",
    "            return decision.model_dump()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Router LLM failed: {e}. Fallback engaged.\")\n",
    "            return self._smart_fallback(query, context)\n",
    "\n",
    "    def _smart_fallback(self, query, context):\n",
    "        q = query.lower()\n",
    "        c = context.lower()\n",
    "\n",
    "        # Если уже есть выход поиска — идём в анализ\n",
    "        if \"search_agent output\" in c or \"найдено\" in c or \"результат поиска\" in c:\n",
    "            return {\n",
    "                \"next_agent\": \"ANALYSIS_AGENT\",\n",
    "                \"reason\": \"Post-search analysis step\",\n",
    "                \"input\": context\n",
    "            }\n",
    "        # Если уже есть анализ — финализируем отчёт\n",
    "        if \"analysis_agent output\" in c or \"анализ\" in c or \"summary\" in c:\n",
    "            return {\n",
    "                \"next_agent\": \"REPORT_AGENT\",\n",
    "                \"reason\": \"Finalize into report\",\n",
    "                \"input\": context\n",
    "            }\n",
    "        # Триггеры «нужна свежесть»\n",
    "        if any(t in q for t in [\"нов\", \"свеж\", \"сегодня\", \"вчера\", \"202\", \"цена\", \"курс\", \"последн\", \"latest\", \"today\", \"news\"]):\n",
    "            return {\"next_agent\": \"SEARCH_AGENT\", \"reason\": \"Fresh info likely needed\", \"input\": query}\n",
    "        # По умолчанию — анализ\n",
    "        return {\"next_agent\": \"ANALYSIS_AGENT\", \"reason\": \"Direct analysis\", \"input\": query}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0b5fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "TRACE_SESSION = \"X-Trace-Session\"\n",
    "TRACE_PARENT = \"X-Parent-Event\"\n",
    "\n",
    "class TraceHeadersMiddleware(BaseHTTPMiddleware):\n",
    "    async def dispatch(self, request: Request, call_next):\n",
    "        sid = request.headers.get(TRACE_SESSION)\n",
    "        if sid:\n",
    "            try:\n",
    "                tracer.session_id = sid\n",
    "            except Exception:\n",
    "                pass\n",
    "        response = await call_next(request)\n",
    "        return response\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0920de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# 2. ПОИСКОВЫЙ АГЕНТ (отдельный сервис)\n",
    "search_app = FastAPI(title=\"search-agent\")\n",
    "search_app.add_middleware(AccessLogMiddleware, service_name=\"search-agent\", log_fn=log_json)\n",
    "\n",
    "duck = DuckDuckGoSearchRun()\n",
    "\n",
    "translate_prompt = PromptTemplate.from_template(\n",
    "    \"Translate to English for web search. Output ONLY the translation, no quotes, no comments:\\n{data}\"\n",
    ")\n",
    "\n",
    "@search_app.post(\"/execute\")\n",
    "async def execute_search(task: TaskRequest, request: Request):\n",
    "    parent = request.headers.get(\"X-Parent-Event\")\n",
    "    root_eid = tracer.start_trace(\n",
    "        agent_name=\"search-agent/execute\",\n",
    "        agent_type=AgentType.SEARCH,\n",
    "        data={\n",
    "            \"trace_headers_present\": bool(parent),\n",
    "            \"input_preview\": (task.input or \"\")[:200]\n",
    "        },\n",
    "        parent_event_id=parent\n",
    "    )\n",
    "\n",
    "    cb = LoggingCallback(log_fn=log_json)\n",
    "    try:\n",
    "        # 1) translate\n",
    "        with trace_block(\"translate\", AgentType.TOOL, parent_event_id=root_eid, original_query=task.input) as trans_eid:\n",
    "            model_name = getattr(llm, \"model_name\", type(llm).__name__)\n",
    "            tool_eid = tracer.log_tool_start(\n",
    "                agent_name=\"translate\",\n",
    "                tool_name=str(model_name),\n",
    "                tool_input={\"data_preview\": (task.input or \"\")[:200]},\n",
    "                parent_event_id=trans_eid\n",
    "            )\n",
    "            try:\n",
    "                english_query = (translate_prompt | llm).invoke({\"data\": task.input}, config={\"callbacks\":[cb]}).strip()\n",
    "                if english_query.startswith('\"') and english_query.endswith('\"'):\n",
    "                    english_query = english_query[1:-1].strip()\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"translation_preview\": english_query[:400]},\n",
    "                    success=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tracer.log_tool_end(tool_eid, tool_output={\"error\": str(e)[:400]}, success=False)\n",
    "                tracer.log_error(\"translate\", e, parent_event_id=trans_eid)\n",
    "                tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "                raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "        # 2) web_search\n",
    "        with trace_block(\"web_search\", AgentType.SEARCH, parent_event_id=root_eid, query=english_query) as search_eid:\n",
    "            tool_eid = tracer.log_tool_start(\n",
    "                agent_name=\"web_search\",\n",
    "                tool_name=\"DuckDuckGoSearchRun\",\n",
    "                tool_input={\"query\": english_query},\n",
    "                parent_event_id=search_eid\n",
    "            )\n",
    "            try:\n",
    "                result = duck.run(english_query)\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"result_preview\": str(result)[:400]},\n",
    "                    success=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tracer.log_tool_end(tool_eid, tool_output={\"error\": str(e)[:400]}, success=False)\n",
    "                tracer.log_error(\"web_search\", e, parent_event_id=search_eid)\n",
    "                tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "                raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "        tracer.end_trace(root_eid, {\"success\": True}, success=True)\n",
    "        return {\"result\": result, \"agent\": \"SEARCH_AGENT\", \"translated_query\": english_query}\n",
    "\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        tracer.log_error(\"search/execute\", e, parent_event_id=root_eid)\n",
    "        tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        tracer.export_traces(\"search_agent.json\", format=\"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7659db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# 3. АГЕНТ-АНАЛИТИК (отдельный сервис)\n",
    "analysis_app = FastAPI()\n",
    "analysis_app.add_middleware(AccessLogMiddleware, service_name=\"analysis-agent\", log_fn=log_json)\n",
    "\n",
    "@analysis_app.post(\"/execute\")\n",
    "async def execute_analysis(task: TaskRequest, request: Request):\n",
    "    parent = request.headers.get(\"X-Parent-Event\")\n",
    "    root_eid = tracer.start_trace(\n",
    "        agent_name=\"analysis-agent/execute\",\n",
    "        agent_type=AgentType.ANALYSIS,\n",
    "        data={\n",
    "            \"trace_headers_present\": bool(parent),\n",
    "            \"input_preview\": (task.input or \"\")[:200]\n",
    "        },\n",
    "        parent_event_id=parent\n",
    "    )\n",
    "\n",
    "    cb = LoggingCallback(log_fn=log_json)\n",
    "    try:\n",
    "        # prepare_prompt\n",
    "        with trace_block(\n",
    "            \"prepare_prompt\",\n",
    "            AgentType.CUSTOM,\n",
    "            parent_event_id=root_eid,\n",
    "            template=\"Analyze this information and extract key insights in Russian\"\n",
    "        ) as prep_eid:\n",
    "            prompt = PromptTemplate.from_template(\"\"\"\n",
    "            Analyze this information and extract key insights in Russian:\n",
    "\n",
    "            {data}\n",
    "\n",
    "            Provide comprehensive analysis in Russian.\n",
    "            \"\"\")\n",
    "            chain = prompt | llm\n",
    "\n",
    "        # llm_inference\n",
    "        with trace_block(\n",
    "            \"llm_inference\",\n",
    "            AgentType.ANALYSIS,\n",
    "            parent_event_id=root_eid,  # <-- важное: родитель — текущий блок, а не prep_eid\n",
    "            tokens_estimate=len((task.input or \"\"))  # просто пример метадаты\n",
    "        ) as infer_eid:\n",
    "            model_name = getattr(llm, \"model_name\", type(llm).__name__)\n",
    "            tool_eid = tracer.log_tool_start(\n",
    "                agent_name=\"llm_inference\",              # <-- это имя пойдёт в граф (будет \"llm_inference::MODEL\")\n",
    "                tool_name=str(model_name),\n",
    "                tool_input={\"data_preview\": (task.input or \"\")[:200]},\n",
    "                parent_event_id=infer_eid                # <-- правильный parent\n",
    "            )\n",
    "            try:\n",
    "                result = chain.invoke({\"data\": task.input}, config={\"callbacks\":[cb]})\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"result_preview\": (str(result) if result is not None else \"\")[:400]},\n",
    "                    success=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"error\": str(e)[:400]},\n",
    "                    success=False\n",
    "                )\n",
    "                tracer.log_error(\"llm_inference\", e, parent_event_id=infer_eid)\n",
    "                tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "                raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "        tracer.end_trace(root_eid, {\"success\": True}, success=True)\n",
    "        return {\"result\": result, \"agent\": \"ANALYSIS_AGENT\"}\n",
    "\n",
    "    except HTTPException:\n",
    "        # уже залогировано выше\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        tracer.log_error(\"analysis-agent/execute\", e, parent_event_id=root_eid)\n",
    "        tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        tracer.export_traces(\"analysis_agent.json\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c074f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# 4. АГЕНТ-ОТЧЕТ (отдельный сервис)\n",
    "report_app = FastAPI()\n",
    "report_app.add_middleware(AccessLogMiddleware, service_name=\"report-agent\", log_fn=log_json)\n",
    "\n",
    "@report_app.post(\"/execute\")\n",
    "async def execute_report(task: TaskRequest, request: Request):\n",
    "    parent = request.headers.get(\"X-Parent-Event\")\n",
    "    root_eid = tracer.start_trace(\n",
    "        agent_name=\"report-agent/execute\",\n",
    "        agent_type=AgentType.REPORT,\n",
    "        data={\n",
    "            \"trace_headers_present\": bool(parent),\n",
    "            \"input_preview\": (task.input or \"\")[:300]\n",
    "        },\n",
    "        parent_event_id=parent\n",
    "    )\n",
    "    try:\n",
    "        cb = LoggingCallback(log_fn=log_json)\n",
    "\n",
    "        # подготовка промпта\n",
    "        with trace_block(\"prepare_prompt\", AgentType.CUSTOM, parent_event_id=root_eid) as prep_eid:\n",
    "            prompt = PromptTemplate.from_template(\n",
    "                \"\"\"Generate comprehensive final answer in Russian based on this information:\n",
    "\n",
    "                {data}\n",
    "\n",
    "                Answer in clear, structured Russian.\"\"\"\n",
    "            )\n",
    "            chain = prompt | llm\n",
    "\n",
    "        # инференс LLM (как инструмент: start -> invoke -> end)\n",
    "        with trace_block(\"llm_inference\", AgentType.REPORT, parent_event_id=prep_eid) as infer_eid:\n",
    "            model_name = getattr(llm, \"model_name\", type(llm).__name__)\n",
    "            tool_eid = tracer.log_tool_start(\n",
    "                agent_name=\"llm_inference\",\n",
    "                tool_name=str(model_name),\n",
    "                tool_input={\"data_preview\": (task.input or \"\")[:200]},\n",
    "                parent_event_id=infer_eid\n",
    "            )\n",
    "            try:\n",
    "                result = chain.invoke({\"data\": task.input}, config={\"callbacks\": [cb]})\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"result_preview\": (str(result) if result is not None else \"\")[:400]},\n",
    "                    success=True\n",
    "                )\n",
    "            except Exception as e:\n",
    "                tracer.log_tool_end(\n",
    "                    tool_eid,\n",
    "                    tool_output={\"error\": str(e)[:400]},\n",
    "                    success=False\n",
    "                )\n",
    "                raise\n",
    "\n",
    "        tracer.end_trace(root_eid, {\"success\": True}, success=True)\n",
    "        return {\"result\": result, \"agent\": \"REPORT_AGENT\"}\n",
    "\n",
    "    except Exception as e:\n",
    "        tracer.log_error(\"report-agent/execute\", e, parent_event_id=root_eid)\n",
    "        tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        tracer.export_traces(\"report_agent.json\", format=\"json\")\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# 5. ГЛАВНЫЙ ОРКЕСТРАТОР (управляет всей системой)\n",
    "orchestrator_app = FastAPI()\n",
    "orchestrator_app.add_middleware(AccessLogMiddleware, service_name=\"orchestrator\", log_fn=log_json)\n",
    "\n",
    "\n",
    "router = RouterAgent(llm)\n",
    "\n",
    "# Маппинг агентов на их URL\n",
    "AGENT_URLS = {\n",
    "    \"SEARCH_AGENT\": \"http://localhost:8001/execute\",\n",
    "    \"ANALYSIS_AGENT\": \"http://localhost:8002/execute\", \n",
    "    \"REPORT_AGENT\": \"http://localhost:8003/execute\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28289d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "for _app in [orchestrator_app, search_app, analysis_app, report_app]:\n",
    "    try:\n",
    "        _app.add_middleware(TraceHeadersMiddleware)\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f934f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "@orchestrator_app.post(\"/orchestrate\")\n",
    "async def orchestrate(task: TaskRequest):\n",
    "    request_id = str(uuid.uuid4())\n",
    "    execution_chain = []\n",
    "    current_data = task.input\n",
    "    context = f\"[{request_id}] Original query: {task.input}\"\n",
    "    last_agent = None\n",
    "    search_runs = 0\n",
    "\n",
    "    # корневое событие запроса оркестратора\n",
    "    root_eid = tracer.start_trace(\n",
    "        agent_name=\"orchestrator/orchestrate\",\n",
    "        agent_type=AgentType.ORCHESTRATOR,\n",
    "        data={\"request_id\": request_id, \"input_preview\": (task.input or \"\")[:300]}\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        for step in range(6):\n",
    "            # ── Роутинг шага\n",
    "            with trace_block(\n",
    "                agent_name=\"router\",\n",
    "                agent_type=AgentType.CLARIFICATION,\n",
    "                parent_event_id=root_eid,\n",
    "                step=step + 1\n",
    "            ) as route_eid:\n",
    "\n",
    "                routing = router.route(task.input if step == 0 else current_data, context)\n",
    "                next_agent = routing[\"next_agent\"]\n",
    "                agent_input = routing[\"input\"]\n",
    "\n",
    "                # Жёсткие перила\n",
    "                if last_agent == \"SEARCH_AGENT\" and next_agent == \"SEARCH_AGENT\":\n",
    "                    next_agent = \"ANALYSIS_AGENT\"\n",
    "                    agent_input = f\"Analyze following search snippets:\\n{current_data[:5000]}\"\n",
    "                if last_agent == \"ANALYSIS_AGENT\" and next_agent == \"ANALYSIS_AGENT\":\n",
    "                    next_agent = \"REPORT_AGENT\"\n",
    "                    agent_input = f\"Generate report from analysis:\\n{current_data[:5000]}\"\n",
    "\n",
    "                if next_agent == \"SEARCH_AGENT\":\n",
    "                    search_runs += 1\n",
    "                    if search_runs > 2:\n",
    "                        next_agent = \"ANALYSIS_AGENT\"\n",
    "                        agent_input = f\"Analyze following search snippets:\\n{current_data[:5000]}\"\n",
    "\n",
    "                agent_url = AGENT_URLS.get(next_agent)\n",
    "                if not agent_url:\n",
    "                    raise RuntimeError(f\"No URL for agent {next_agent}\")\n",
    "\n",
    "                # лог «сообщения» (для диаграммы последовательности)\n",
    "                tracer.log_message(\n",
    "                    from_agent=\"orchestrator\",\n",
    "                    to_agent=next_agent,\n",
    "                    message=f\"step={step+1}, reason={routing.get('reason','')}, input_preview={agent_input[:180]}\",\n",
    "                    parent_event_id=route_eid\n",
    "                )\n",
    "                await log_trace(\n",
    "                    event=\"route\",\n",
    "                    request_id=request_id,\n",
    "                    step=step + 1,\n",
    "                    next_agent=next_agent,\n",
    "                    reason=routing.get(\"reason\", \"\"),\n",
    "                    agent_input_preview=agent_input[:300]\n",
    "                )\n",
    "\n",
    "            with trace_block(\n",
    "                agent_name=f\"http_call::{next_agent}\",\n",
    "                agent_type=AgentType.TOOL,\n",
    "                parent_event_id=route_eid,\n",
    "                url=agent_url\n",
    "            ) as http_eid:\n",
    "\n",
    "                HTTP_HEADERS = {\n",
    "                    \"X-Trace-Session\": tracer.session_id,\n",
    "                    \"X-Parent-Event\": http_eid,\n",
    "                }\n",
    "\n",
    "                tool_eid = tracer.log_tool_start(\n",
    "                    agent_name=f\"http_call::{next_agent}\",   # <-- одинаковый agent_name в start и end\n",
    "                    tool_name=\"HTTP POST\",\n",
    "                    tool_input={\"url\": agent_url, \"json\": {\"input\": agent_input[:500]}},\n",
    "                    parent_event_id=http_eid\n",
    "                )\n",
    "\n",
    "                try:\n",
    "                    async with aiohttp.ClientSession() as session:\n",
    "                        async with session.post(agent_url, json={\"input\": agent_input}, headers=HTTP_HEADERS) as resp:\n",
    "                            body_text = await resp.text()\n",
    "                            if resp.status != 200:\n",
    "                                tracer.log_tool_end(\n",
    "                                    tool_eid,\n",
    "                                    tool_output={\"status\": resp.status, \"body\": body_text[:400]},\n",
    "                                    success=False\n",
    "                                )\n",
    "                                tracer.log_error(f\"http_call::{next_agent}\",\n",
    "                                                RuntimeError(f\"HTTP {resp.status}: {body_text[:400]}\"),\n",
    "                                                parent_event_id=http_eid)\n",
    "                                raise RuntimeError(f\"{next_agent} failed: {body_text}\")\n",
    "\n",
    "                            payload = await resp.json()\n",
    "                            current_data = payload[\"result\"]\n",
    "                            tracer.log_tool_end(\n",
    "                                tool_eid,\n",
    "                                tool_output={\"status\": resp.status, \"result_preview\": str(current_data)[:400]},\n",
    "                                success=True\n",
    "                            )\n",
    "\n",
    "                except Exception as e:\n",
    "                    # чтобы end-тул под любой ошибкой точно был написан (если не успели выше)\n",
    "                    try:\n",
    "                        tracer.log_tool_end(tool_eid, tool_output={\"error\": str(e)[:400]}, success=False)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                    tracer.log_error(f\"http_call::{next_agent}\", e, parent_event_id=http_eid)\n",
    "                    raise\n",
    "\n",
    "            # обновляем контекст и цепочку\n",
    "            context += f\" | {next_agent} output: {current_data[:400]}\"\n",
    "            execution_chain.append({\n",
    "                \"step\": step + 1,\n",
    "                \"agent\": next_agent,\n",
    "                \"input\": (agent_input or \"\")[:250],\n",
    "                \"output\": (current_data or \"\")[:250]\n",
    "            })\n",
    "            last_agent = next_agent\n",
    "\n",
    "            if next_agent == \"REPORT_AGENT\":\n",
    "                break\n",
    "\n",
    "        # успех — закрываем корень\n",
    "        tracer.end_trace(root_eid, {\"success\": True}, success=True)\n",
    "        return {\n",
    "            \"final_result\": current_data,\n",
    "            \"execution_chain\": execution_chain,\n",
    "            \"trace_id\": request_id,\n",
    "            \"status\": \"completed\" if last_agent == \"REPORT_AGENT\" else \"max_steps_reached\"\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        # ошибка — логируем и закрываем корень с флагом fail\n",
    "        logging.exception(f\"[{request_id}] Orchestration error: {e}\")\n",
    "        tracer.log_error(\"orchestrator/orchestrate\", e, parent_event_id=root_eid)\n",
    "        tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "        return {\n",
    "            \"final_result\": f\"Error: {e}\",\n",
    "            \"execution_chain\": execution_chain,\n",
    "            \"trace_id\": request_id,\n",
    "            \"status\": \"error\"\n",
    "        }\n",
    "    finally:\n",
    "        tracer.export_traces(\"orchestrator_trace.json\", format=\"json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783365e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "@orchestrator_app.post(\"/test_router\")\n",
    "async def test_router(task: TaskRequest):\n",
    "    \"\"\"Тестовый эндпоинт для проверки работы роутера\"\"\"\n",
    "    # Корневой эвент запроса\n",
    "    root_eid = tracer.start_trace(\n",
    "        agent_name=\"orchestrator/test_router\",\n",
    "        agent_type=AgentType.ORCHESTRATOR,\n",
    "        data={\"input_preview\": (task.input or \"\")[:300]}\n",
    "    )\n",
    "    try:\n",
    "        # Отдельный блок для принятия решения роутером\n",
    "        with trace_block(\n",
    "            agent_name=\"router\",\n",
    "            agent_type=AgentType.CLARIFICATION,\n",
    "            parent_event_id=root_eid\n",
    "        ) as route_eid:\n",
    "            routing = router.route(task.input)\n",
    "\n",
    "            # Лог «сообщения» для диаграммы последовательности\n",
    "            tracer.log_message(\n",
    "                from_agent=\"orchestrator\",\n",
    "                to_agent=routing.get(\"next_agent\", \"UNKNOWN\"),\n",
    "                message=f\"router_decision: {routing}\",\n",
    "                parent_event_id=route_eid\n",
    "            )\n",
    "\n",
    "        response = {\n",
    "            \"input\": task.input,\n",
    "            \"routing_decision\": routing,\n",
    "            \"agent_url\": AGENT_URLS.get(routing[\"next_agent\"])\n",
    "        }\n",
    "\n",
    "        # Успешное закрытие корневого эвента\n",
    "        tracer.end_trace(root_eid, {\"success\": True}, success=True)\n",
    "        return response\n",
    "\n",
    "    except Exception as e:\n",
    "        # Ошибочное закрытие + запись ошибки\n",
    "        tracer.log_error(\"orchestrator/test_router\", e, parent_event_id=root_eid)\n",
    "        tracer.end_trace(root_eid, {\"error\": str(e)}, success=False)\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "    finally:\n",
    "        tracer.export_traces(\"orchestrator_test_router_trace.json\", format=\"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b5a2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17907d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# Health checks\n",
    "@orchestrator_app.get(\"/health\")\n",
    "async def health():\n",
    "    return {\"status\": \"healthy\", \"service\": \"orchestrator\"}\n",
    "\n",
    "@search_app.get(\"/health\")\n",
    "async def search_health():\n",
    "    return {\"status\": \"healthy\", \"service\": \"search_agent\"}\n",
    "\n",
    "@analysis_app.get(\"/health\")\n",
    "async def analysis_health():\n",
    "    return {\"status\": \"healthy\", \"service\": \"analysis_agent\"}\n",
    "\n",
    "@report_app.get(\"/health\")\n",
    "async def report_health():\n",
    "    return {\"status\": \"healthy\", \"service\": \"report_agent\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea66092",
   "metadata": {},
   "source": [
    "# Подтягиваем порты апишек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "595e3d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [13484]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     Started server process [13484]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8001 (Press CTRL+C to quit)\n",
      "INFO:     Started server process [13484]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
      "INFO:     Started server process [13484]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-agent system is running on ports 8000-8003\n"
     ]
    }
   ],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "def run_server(app, port, log_file):\n",
    "    \"\"\"Запускает FastAPI сервер на указанном порту\"\"\"\n",
    "    logging.basicConfig(\n",
    "        filename=log_file, \n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        logging.info(f\"Starting server on port {port}\")\n",
    "        uvicorn.run(\n",
    "            app, \n",
    "            host=\"0.0.0.0\", \n",
    "            port=port, \n",
    "            log_level=\"info\",\n",
    "            access_log=False  # Убираем лишние логи\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Server failed to start on port {port}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Освобождаем порты перед запуском\n",
    "def free_port(port):\n",
    "    \"\"\"Освобождает порт если он занят\"\"\"\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            if s.connect_ex(('localhost', port)) == 0:\n",
    "                # Порт занят, пытаемся освободить\n",
    "                for proc in psutil.process_iter(['pid', 'name']):\n",
    "                    try:\n",
    "                        for conn in proc.net_connections():\n",
    "                            if conn.laddr.port == port:\n",
    "                                proc.terminate()\n",
    "                                proc.wait(timeout=2)\n",
    "                                logging.info(f\"Freed port {port} from process {proc.pid}\")\n",
    "                    except (psutil.NoSuchProcess, psutil.AccessDenied):\n",
    "                        pass\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Could not free port {port}: {str(e)}\")\n",
    "\n",
    "# Освобождаем все нужные порты\n",
    "for port in [8000, 8001, 8002, 8003]:\n",
    "    free_port(port)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Запускаем все сервисы\n",
    "services = [\n",
    "    (orchestrator_app, 8000, \"orchestrator\"),\n",
    "    (search_app, 8001, \"search_agent\"), \n",
    "    (analysis_app, 8002, \"analysis_agent\"),\n",
    "    (report_app, 8003, \"report_agent\")\n",
    "]\n",
    "\n",
    "for app, port, name in services:\n",
    "    threading.Thread(\n",
    "        target=run_server, \n",
    "        args=(app, port, f\"{name}.log\"),\n",
    "        daemon=True  # Демонизируем потоки\n",
    "    ).start()\n",
    "    time.sleep(2)  # Пауза между запуском сервисов\n",
    "\n",
    "logging.info(\"All agents started successfully!\")\n",
    "print(\"Multi-agent system is running on ports 8000-8003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f23cf84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System Status: {'system_status': 'healthy', 'agent_status': {'orchestrator': True, 'search_agent': True, 'analysis_agent': True, 'report_agent': True}}\n"
     ]
    }
   ],
   "source": [
    "# file: agent_with_orchestration.py\n",
    "# System Status Monitor\n",
    "class SystemMonitor:\n",
    "    def __init__(self):\n",
    "        self.agent_status = {\n",
    "            \"orchestrator\": False,\n",
    "            \"search_agent\": False,\n",
    "            \"analysis_agent\": False,\n",
    "            \"report_agent\": False\n",
    "        }\n",
    "    \n",
    "    async def check_all_services(self):\n",
    "        for service, port in [\n",
    "            (\"orchestrator\", 8000),\n",
    "            (\"search_agent\", 8001),\n",
    "            (\"analysis_agent\", 8002),\n",
    "            (\"report_agent\", 8003)\n",
    "        ]:\n",
    "            try:\n",
    "                async with aiohttp.ClientSession() as session:\n",
    "                    async with session.get(f\"http://localhost:{port}/health\", timeout=5) as response:\n",
    "                        if response.status == 200:\n",
    "                            self.agent_status[service] = True\n",
    "                            logging.info(f\"{service} is healthy\")\n",
    "                        else:\n",
    "                            self.agent_status[service] = False\n",
    "                            logging.warning(f\"{service} returned status {response.status}\")\n",
    "            except Exception as e:\n",
    "                self.agent_status[service] = False\n",
    "                logging.error(f\"{service} health check failed: {str(e)}\")\n",
    "    \n",
    "    def all_services_healthy(self):\n",
    "        return all(self.agent_status.values())\n",
    "\n",
    "    def get_status_report(self):\n",
    "        return {\n",
    "            \"system_status\": \"healthy\" if self.all_services_healthy() else \"degraded\",\n",
    "            \"agent_status\": self.agent_status\n",
    "        }\n",
    "\n",
    "# Initialize system monitor\n",
    "system_monitor = SystemMonitor()\n",
    "\n",
    "# Run initial health check\n",
    "await system_monitor.check_all_services()\n",
    "print(\"System Status:\", system_monitor.get_status_report())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee7b669",
   "metadata": {},
   "source": [
    "# Тест промпт\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2aa64a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: Какая сегодня погода в Москве?\n",
      "Status: max_steps_reached\n",
      "Steps: 6\n",
      "\n",
      "Step 1 - SEARCH_AGENT:\n",
      "   Input: Какая сегодня погода в Москве?...\n",
      "   Output: 3 days ago - Due to the significant variation in temperature between the winter ...\n",
      "\n",
      "Step 2 - ANALYSIS_AGENT:\n",
      "   Input: Analyze following search snippets:\n",
      "3 days ago - Due to the significant variation...\n",
      "   Output: Из представленных поисковых сниппетов можно извлечь следующие ключевые моменты:\n",
      "...\n",
      "\n",
      "Step 3 - SEARCH_AGENT:\n",
      "   Input: Какая сегодня погода в Москве?...\n",
      "   Output: 4 uur geleden — Current weather in Moscow and forecast for today, tomorrow, and ...\n",
      "\n",
      "Step 4 - ANALYSIS_AGENT:\n",
      "   Input: Какая сегодня погода в Москве?...\n",
      "   Output: Запрос «Какая сегодня погода в Москве?» направлен на получение информации о пого...\n",
      "\n",
      "Step 5 - ANALYSIS_AGENT:\n",
      "   Input: Analyze following search snippets:\n",
      "Запрос «Какая сегодня погода в Москве?» напра...\n",
      "   Output: Запрос «Какая сегодня погода в Москве?» направлен на получение информации о пого...\n",
      "\n",
      "Step 6 - ANALYSIS_AGENT:\n",
      "   Input: Analyze following search snippets:\n",
      "Запрос «Какая сегодня погода в Москве?» напра...\n",
      "   Output: Запрос «Какая сегодня погода в Москве?» направлен на получение информации о пого...\n",
      "\n",
      "Final result: Запрос «Какая сегодня погода в Москве?» направлен на получение информации о погодных условиях в Москве на текущий день. \n",
      "\n",
      "Ключевые моменты запроса:\n",
      "1. Пользователь хочет узнать текущую погоду.\n",
      "2. Инте...\n"
     ]
    }
   ],
   "source": [
    "async def debug_test():\n",
    "    \"\"\"Тест с детальным логированием\"\"\"\n",
    "    test_query = \"Какая сегодня погода в Москве?\"\n",
    "    \n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.post(\n",
    "            \"http://localhost:8000/orchestrate\",\n",
    "            json={\"input\": test_query}\n",
    "        ) as response:\n",
    "            result = await response.json()\n",
    "            \n",
    "            print(f\"\\nQuery: {test_query}\")\n",
    "            print(f\"Status: {result['status']}\")\n",
    "            print(f\"Steps: {len(result['execution_chain'])}\")\n",
    "            \n",
    "            for step in result['execution_chain']:\n",
    "                print(f\"\\nStep {step['step']} - {step['agent']}:\")\n",
    "                print(f\"   Input: {step['input'][:80]}...\")\n",
    "                print(f\"   Output: {step['output'][:80]}...\")\n",
    "            \n",
    "            print(f\"\\nFinal result: {result['final_result'][:200]}...\")\n",
    "\n",
    "# Запускаем тест\n",
    "asyncio.run(debug_test())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4a757",
   "metadata": {},
   "source": [
    "# Работа со streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23ed537b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit запущен: http://localhost:8501\n",
      "Логи пишутся в streamlit.log\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, socket, time, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PORT = 8501  # при необходимости измените порт\n",
    "APP  = \"streamlit_app.py\"  # путь к вашему app\n",
    "\n",
    "# Если уже запущен на этом порту — выберите другой\n",
    "def port_open(port):\n",
    "    with socket.socket() as s:\n",
    "        s.settimeout(0.2)\n",
    "        return s.connect_ex((\"127.0.0.1\", port)) == 0\n",
    "\n",
    "if port_open(PORT):\n",
    "    print(f\"Порт {PORT} уже занят. Поменяйте PORT или остановите другой процесс.\")\n",
    "else:\n",
    "    # Запускаем streamlit тем же интерпретатором, что и Jupyter\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"streamlit\", \"run\", APP,\n",
    "        \"--server.headless\", \"true\",\n",
    "        \"--server.port\", str(PORT)\n",
    "    ]\n",
    "    # stdout/stderr можно писать в файл, чтобы не засорять вывод\n",
    "    log_file = open(\"streamlit.log\", \"w\", encoding=\"utf-8\")\n",
    "    proc = subprocess.Popen(cmd, stdout=log_file, stderr=subprocess.STDOUT)\n",
    "\n",
    "    # Подождём, пока сервер поднимется\n",
    "    for _ in range(60):\n",
    "        if port_open(PORT):\n",
    "            break\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    if port_open(PORT):\n",
    "        print(f\"Streamlit запущен: http://localhost:{PORT}\")\n",
    "        print(\"Логи пишутся в streamlit.log\")\n",
    "    else:\n",
    "        print(\"Не удалось запустить Streamlit (проверьте streamlit.log)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df17b8",
   "metadata": {},
   "source": [
    "# Освобождение порта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d77be32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завершаю PID 16340\n",
      "Завершаю PID 16412\n"
     ]
    }
   ],
   "source": [
    "import psutil, os\n",
    "\n",
    "def kill_on_port(port):\n",
    "    for p in psutil.process_iter(attrs=[\"pid\",\"name\",\"cmdline\"]):\n",
    "        try:\n",
    "            cmd = \" \".join(p.info.get(\"cmdline\") or [])\n",
    "            if \"streamlit\" in cmd and f\"--server.port {port}\" in cmd:\n",
    "                print(\"Завершаю PID\", p.pid)\n",
    "                p.terminate()\n",
    "        except (psutil.AccessDenied, psutil.NoSuchProcess):\n",
    "            pass\n",
    "\n",
    "kill_on_port(PORT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
